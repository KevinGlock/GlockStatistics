<!DOCTYPE html>
<html lang="de">
<!--Discription-->
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>GlockStatistics. Statistical Consulting and Tutoring</title>
	<meta name="description" content="Website of GlockStatistics. Statistical Consulting and Tutoring">
	<meta name="author" content="Kevin Glock">
	<meta name="copyright" content="© Kevin Glock 2020">
<link href="../css/dark.style.css" rel="stylesheet" type="text/css">
</head>
<!--End Discription-->
<body>
	<button onclick="topFunction()" id="myBtn" title="GoUp!">^</button> 
	
<!--Add Icons for light and dark modes-->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<!--header>
</header-->
<!--Navbar-->
<div class="navbar">
  <a class="active" href="../dark/index.html">Home</a>
	<div class="dropdown">
		<button class="dropbtn">Person
		<i class="fa fa-caret-down"></i>
		</button>
    <div class="dropdown-content">
  <a href="../dark/person.html">About</a>
  <a href="../dark/edu.html">Education</a>
  <a href="../dark/work.html">Work</a>
    </div>
	</div>
	<div class="dropdown">
		<button class="dropbtn">Services
		<i class="fa fa-caret-down"></i>
		</button>
    <div class="dropdown-content">
  <a href="../dark/tutoring.html">Tutoring</a>
  <a href="../dark/analyses.html">Analyses</a>
  <a href="../dark/consulting.html">Consulting</a>
    </div>
	</div>
  <a href="../dark/examples.html">Examples</a>
<!--End website links-->
<!--Light Mode Select-->
<div class="mode" style="margin-right: 50px;">
	<div class="light" style="float: right; position:relative; display:inline;">
		<a class="light-link" href="../stats/chance.html"><i class="fa fa-circle-o"></i></a> <!--light-->
	</div>
		<a style="float: right; position: relative; display: inline;">|</a>
			<div class="dark" style="float: right; position: relative;">
				<a class="dark-link" href="chance.html"><i class="fa fa-circle"></i></a> <!--dark-->
			</div>
</div>
<!--End Light Mode Select-->
<!--Language Select-->
<div class="languageSelect col-xs-3 col-sm-7 col-md-8" style="margin-right: 20px;">
	<div class="tx-srlanguagemenu tx-srlanguagemenu-links">
		<div class="CUR" style="float: right; position: relative; display: inline;">
			<a class="linked-language" href="chance.html">DE</a>
		</div>
		<a style="float: right; position: inherit; display: inline;">|</a>
			<div class="NO SPC" style="float: right;">
				<a class="linked-language" href="../dark_stats_en/chance.html">EN</a>
			</div>
	</div>
</div>
<!--End Language Select-->
</div>
<!--End Navbar-->
<main style="margin-top: 120px;">	
  <div id="content">
		<div id="chance">
	
	<h1>Was ist Wahrscheinlichkeit?</h1>
	
	<h4>20. Juni 2020</h4>
	
	<p>Es gibt verschiedene theoretische Ansätze was Wahrscheinlichkeit überhaupt ist<sup>
		<a id="fn27" title="Precht. 1987. S.62-83." href="../sites/footnotes.html#fn27">[27]</a>
		<a id="fn28" title="Grus. 2016. Kap. 6." href="../sites/footnotes.html#fn28">[28]</a></sup>.
Grob werden <b>subjektive und objektive Wahrscheinlichkeit</b> unterschieden. Die auf unterschiedlichen Sichtweisen auf Wahrscheinlichkeit fußen.
	Dabei haben sich in der Historie der Mathematik im Bereich der Wahrscheinlichkeitstheorie ebenso wie in anderen Forschungsdisziplinen verschiedene Schulen entwickelt die unabhängig von einander stark ausgebaut wurden.
	Dabei werden</p> 
	
	<ul>
	<li>die klassische Inferenz-Statistik und</li>
	<li>bayesianische Inferenz (Bayes-Statistik) unterschieden.</li>
	<li>Daneben gibt es die statistische Entscheidungsstrategie als weiteren Strang (nach Wald).</li>
	</ul>
	
	<p>Die klassische Inferenz-Statistik wurde neben anderen von Ronald A. Fisher begründet (objektiver Wahrscheinlichkeitsbegriff).</p>
	
	<p>Nach der <b>klassischen Statistik</b> ist:</p>
		<ul>
	<li>Wahrscheinlichkeit eine Langzeitbetrachtung (<b>frequentistische Sichtweise</b>).</li>
	<li>wahre Parameter in der Grundgesamtheit sind unbekannt und</li>
	<li>können nur mittels konsistenten, effizenten, unverzerrten und erwartungstreuen Schätzers geschätzt werden.</li>
	<li>Eine Beobachtung muss sehr häufig (möglichst unendlich oft) zeitlich und räumlich wiederholt werden (<b>Gesetz der großen Zahl</b>).</li>
	<li>Eine Punktschätzung gilt demnach als sicher, wenn</li>
	<li>sie nahezu immer eintritt, oder in 99,999% der Fälle. Dies wird mit <b>Signifikanztests</b> überprüft.</li>
	<li>Es gibt aber immer die Möglichkeit des Gegenereignisses, also den möglichen nicht Eintritts (<b>Irrtumswahrscheinlichkeit</b>).</li>
	<li>Dies entspricht der regulativen Idee von Wahrheit bei Popper (siehe Kapitel Gütekriterien).</li>
	</ul>
	
	<p>Aus Sicht der Herangehensweise waren Fisher´s wissenschaftlichen Opponenten Thomas Bayes und Pierre-Simon Laplace,
	die die Bayes-Inferenz bereits vor Fisher begründeten (subjektiver Wahrscheinlichkeitsbegriff). Fisher lehnte die bedingte Wahrscheinlichkeit wie sie sie begründeten vehement ab um Theorien zu testen und propagierte erfolgreich die Durchsetzung des Signifikanztestes und den Status quo der objektiven Wahrscheinlichkeit.<p>
	<p>Die Bayes-Statistik nahm sich nähmlich heraus zu behaupten, dass jedem <b>Parameter eine Wahrscheinlichkeit zugeordnet</b> werden kann. Man betrachtet schließlich Daten, die ja nur bei genügender Grundlage den wahrscheinlichsten Parameter als wahren Wert abbilden.
	Hingegen vertritt jedoch die klassische Inferenz, dass <b>wahre Parameter immer unbekannt</b> sind und nur geschätzt werden können. Hypothesen sind also nicht bedingt auf die Daten zu betrachten, sondern Daten bedingt auf eine Hypothese, die gegen eine Nullhypothese zu testen sei.
	Nur in der Langzeitbetrachtung können wir so einen wahren Wert approximieren, sicher können wir uns dennoch nie sein.</p>
	
	<p>Wahrscheinlichkeit ist nach <b>Bayes Auffassung</b>:</p>
	
	<ul>
	<li>eine subjektive mutmaßliche Wettaussage, die im Vorhinein (<b>a-priori</b>)</li>
	<li>gegeben der Daten mutmaßlich (<b>Likelihood</b>)</li>
	<li>als plausibel oder unplausibel im Nachhinein (<b>a-posteriori</b>) entschieden werden kann.</li>
	<li>Folglich geben große Datenmengen mehr Anlass für Plausiblität einer zu testenden Aussage.</li>
	</ul>
	<p>Die Wahrscheinlichkeit für eine als vorläufig richtig oder falsche Aussage setzt sich also aus einem Prior als Vorinformation und Daten bedingt auf diese Vorinformation in Relation zu der Datengrundlage zusammen.</p>
	<p>Diese Sichtweise auf Wahrscheinlichkeit kennt jeder persönlich aus seiner Erfahrung und macht in der Praxis häufig mehr Sinn,
	erscheint aber im Vergleich zur klassischen Wahrscheinlichkeit als unwissenschaftlich um Hypothesen zu überprüfen
	(zumindest für Personen, die sich eher als FrequentistInnen identifizieren). Jedoch nutzen auch FrequentistInnen (un)bewusst in ihrer Praxis eher beysianische Wege für die Interpretation von Daten auch, wenn häufig Objektivität als Maßstab genutzt wird.</p>
	<p>Verdeutlichen wir dies an einem einfachen <b>Beispiel:</b></p>
	
	<p><b>Mutmaßlich</b> hat jeder von uns hat schonmal eine Person in seinem Leben getroffen, die er nicht möchte und nicht sagen kann woran es lag (<b>subjektiver Eindruck</b>).
	Diese Person war vielleicht ArbeitskollegIn, eine Person im Freundeskreis oder einfach auf der Straße. Dies entspräche einem Vorurteil bzw. einer Vorannahme (<b>Prior</b>), einer a-priori Annahme ohne Vorinformation
	(Annahmen ohne Vorinformation nennt man in der Bayes-Statistik zufällig meist unechte bzw. <b>improper Prior</b>, man sollte als keine Annahmen ohne Vorinformation treffen: Wenn wir nichts wissen, wissen wir nichts! Wir lernen hier also schon, hab keine Vorurteile, sie sind meist falsch und unpassend!).
	Nun ist es wohl oder übel so, dass man diese Person nun sehr häufig über längere Zeit trifft, Kontakt zu ihr hat und mit ihr interagiert. Von Mal zu Mal wird die Vorannahme aufgeweicht und du merkst sie ist gar nicht so unsympatisch wie zu Beginn vermutet.
	Durch deine Datengrundlage (jeder Tag als einzelne Stichprobe) hat sich dein Eindruck verändert. Deine Mutmaßlichkeit (<b>Likelihood</b>) hat sich zu Gunsten deiner Datengrundlage verändert.
	Vielleicht musst du eines Tages lange mit dieser Person interagieren und sie sagt etwas zu dir, was du als sehr nett empfandest und nicht erwartet hättest. Das ändert deine Vorannahme vollständig und die beginst die Person von dem Tag an zu mögen, vielleicht werdet ihr sogar Freunde.
	Deine resultierende a-posteriori Annahme ist nun, dass die Person ein netter Mensch ist (<b>Posterior</b>).</p>
	<p>Die Bayes-Inferenz lehrt uns also, dass wir immer Vorannahmen (Hypothesen) haben, die wir anhand von Daten (Stichprobe) zu(un)gunsten dieser Hypothese entscheiden und als vorläufig bestätigt ansehen oder ablehnen sollten.
	Grundlage sollte dabei natürlich immer eine zufällige Stichprobe mit genügender Datengrundlage sein, um überhaupt entscheidbar Aussagen tätigen zu können.</p>
	
	<p>Aus der Praxis wissen wir leider, dass Vorannahmen auch im Kontext von Signifikanztestes häufig geschehen,
	da das Forscherteam vielleicht nicht von ihren Ergebnissen begeistert ist und man sich ein signifikantes Ergebnis gewünscht hat, um im renommierten Journal zu publizieren.
	Wenn Daten oder Tests manipuliert werden, um künstlich signifikante Ergebnisse zu erhalten, sprechen wir von <b>p-Hacking</b>.
	Hier wiegt dann die Vorannhame wohl schwerer und die Faktenlage wird nicht akzeptiert.</p>
	
	<p>Das einfache Prinzip, was Laplace begründete war das <b>Laplace-Experiment</b>.<br>
	<b>Laplace formulierte,</b></p>
	
	<ul>
	<li>dass endlich viele Ergebnisse alle die gleiche Wahrscheinlichkeit</li>
	<li>in einem Zufallsexperiment (bspw. ein Würfelwurf, Münzwürf, eine zufällig gezogenen Stichprobe von Befragten, ...) auszeichnet,</li>
	<li>sodass für die Wahrscheinlichkeit das A eintritt, also P(A) (Probability of A) gilt, dass sie</li>
	<li>die Anzahl der Ergebnisse, bei denen das Ereignis  A  eintritt in Relation zur Gesamtanzahl aller möglichen Ereignisse darstellt.</li>
	<li>Oder formell: die Wahrscheinlichkeit von A ist die Mächtigkeit von A durch die Mächtigkeit der Ereignismenge Omega:</li>
	</ul>
	
	<math>
	<mn>P(A)</mn>
	<mo>=</mo>
	<mfrac bevelled="false">
	<mi>|A|</mi>
	<mi>|Ω|</mi>
	</mfrac>
	</math>
	
	<p>Dieses Prinzip findet sich im Kapitel Klassen und Intervalle als relative Häufigkeiten.
	Hier wird dieses Prinzip lediglich anstatt auf beobachtete Ausprägungen auf die Wahrscheinlichkeit des Eintreten von Ereignissen übertragen.
	Daher wird meist ein Würfel oder eine Münze als Beispiel genutzt. Ein Würfel hat 6 Seiten, alle Seiten treten gleich wahrscheinlich mit
	<math>
		<mn>P(A)</mn>
	<mo>=</mo>
	<mfrac bevelled="false">
		<mi>|1|</mi>
		<mi>|6|</mi>
	</mfrac>
	</math> ein. Bei einer Münze haben ebenso beide Seiten die gleiche Wahrscheinlichkeit des Eintritts mit 50 Porzent, also ein Chancenverhältnis von 50:50.</p>
	
	<h1>Was ist die Chance?</h1>

		<p>Die Chance ist das Verhältnis zweier Größen in einer 2x2 Kreuztabelle. Sie ist ein simples Maß um auf Wahrscheinlichkeiten zu schließen.
		Häufig hört man im Kontext von medizinischen Aussagen oder im Glücksspiel, meist auch gemeinsam mit einem Risiko.</p>

		<ul>
		<li>Rauchen erhöht das Risiko an Herz-Kreislauf-Erkrankungen zu erkranken.</li>
		<li>Die Chance im Lotto zu gewinnen liegt bei 1:64 Millionen.</li>
		<li>Laut Angaben des Bundesgesundheitsministeriums aus dem Jahr 2020 sind 8,7 Prozent der Kinder
		zwischen 3 und 17 Jahren übergewichtig.
		Das entspricht einem Chancenverhältnis von 1 zu 11,
		also etwa jedes elfte Kind in Deutschland weißt Übergewicht auf, jedes 16. ist adipös<sup>
		<a id="fn29" title="Bundesgesundheitsministerium. 2020." href="https://www.bundesgesundheitsministerium.de/themen/praevention/kindergesundheit/praevention-von-kinder-uebergewicht.html">[29]</a>
		</sup>.</li>
		</ul>
	
	<h2>Hund oder Katze?</h2>
		
		<p>Welches ist das beliebteste Haustier der Deutschen? Hund! Nein, Katze! Oder doch der Wellensittich?
		Folgt man den Aussagen der Marktforschung, zeigen sich unterschiedliche Ergebnisse. Mal ist es der Hund, mal ist es die Katze.
		Vermutlich kann man sich hier gar nicht wirklich einigen. Es ist wohl eine 50:50 oder 1:1 Chance zwischen Hunden und Katzen.
		In diesem Fall ist die Chance bedingt auf das Spaltenverhältnis. Also das Verhältnis ob Hund oder Katze angegeben wird (bzw. als Ereignis eintritt).
		Haustierbesitzer decken in diesem Fall nur die Ausprägungen Hund oder Katze ab; nicht beides, keins, oder andere.
		Man könnte dies also als einfachen Münzwurf auffassen, entweder Kopf oder Zahl, Katze oder Hund.
		</p>

		<p>
		Folgen wir Google Trends, zeigt sich ein klares gestiegenes Interesse in der Zeit von COVID-19 und HomeOffice in Deutschland, was damit assoziert sein könnte, dass mehr Leute Zeit für
		und Interesse an einem Hund als Haustier haben, um der sozialen Distanz zu entkommen. Von vormalige Beliebtheitswert ist von 75 Indexpunkten auf 100 gestiegen und zeigt damit größte Beliebtheit in den Suchanfragen an.
		Katzen hingegen sind konstant beliebt bei um die 30 Indexpunkten auf der Beliebtheitsskala.
		</p>
		  <script type="text/javascript" src="https://ssl.gstatic.com/trends_nrtr/2213_RC01/embed_loader.js"></script>
  <script type="text/javascript">
    trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"Hund","geo":"DE","time":"today 12-m"},{"keyword":"Katze","geo":"DE","time":"today 12-m"}],"category":0,"property":""}, {"exploreQuery":"geo=DE&q=Hund,Katze&date=today 12-m,today 12-m","guestPath":"https://trends.google.de:443/trends/embed/"});
  </script>
		(Eine Modellierung von GoogleTrends, die die Beliebtheit der Suchbegriffe "Hund" und "Katze" in Deutschland darstellt.)</p>
		
		<p>
		Wie bereits im Kapitel Realität und Modelle erwähnt wurde, ist die Welt nicht binär, auch in diesem Fall nicht.
		Würde man weitere Kategorien mit einbeziehen (Kleintierbesitzer, Aquaristen, ...) würde sich die Wahrscheinlichkeit weiter dezimieren.
		Die größten Wahrscheinlichkeiten hätten aber wohl die Katzen- oder Hundebesitzenden in zufällig gezogenen Stichproben aufzutreten.
		</p>
		
	<h2>Wodurch wird es bedingt ein Haustier als Familienmitglied zu haben?</h2>
		
		<p>Es gibt sehr viele Gründe warum Menschen ein Haustier als neues Familienmitglied aufnehmen. Welche fallen dir spontan ein?
		Hast du vielleicht ein Haustier oder jemand in deiner Familie? Dann weißt du vermutlich warum.</p>
		
		<p>Wahrscheinlichkeit ist also eine Hypothese, die bedingt auf Evidenz Betrachtung findet und als wahrscheinlich plausibel oder unplausibel angesehen werden kann.</p>
		
		<math>
		<mn>P(H|E)</mn>
	<mo>=</mo>
	<mfrac bevelled="false">
		<mi>P(H)*P(E|H)</mi>
		<mi>P(E)</mi>
	</mfrac>
	</math>
	
		<p>Haustiere fungieren als treuer Partner, machen den Alltag manchmal lebenswerter und sind Spielpartner, Freund und besonders Hunde häufig auch Beschützer.
		Daraus folgt, dass besonders Familien mit Kindern, einsame Personen, ältere Personen sowie Landbesitzer Tiere in ihrer Familie haben.
		Wenn man dies also in einer Kontingenztabelle darstellt, müssten diese Personen, im Verhältnis zu Personen, die diese Merkmale nicht aufweisen, häufiger ein Tier besitzen.
		Wenn aber es andere Faktoren (Eigenschaftsdimensionen) der Personenkreise es bedingen ein Haustier zu haben, müssten die Häufigkeiten im Vergleich ungefähr gleich sein.<br>
		Dies nennt man dann <b>stochastische Unabhängigkeit</b>.<br></p>

		<ul>
		<li>Zwei statistische Variablen heißen stochastisch unabhängig, wenn die relativen Häufigkeiten
		<math>
			<msub>
			<mi>h</mi>
			<mn>ij</mn>
			</msub>
		</math>
		in den Zellen, dem Produkt der relativen Randhäufigkeiten aus Zeile und Spalte
		<math>
			<msub>
			<mi>h</mi>
			<mn>ij</mn>
			</msub>
		<mo>=</mo>
		<msub>
			<mi>h</mi>
			<mn>i.</mn>
			</msub>
			<mo>*</mo>
		<msub>
			<mi>h</mi>
			<mn>.j</mn>
			</msub>
		</math>
		entspricht.</li>
		</ul>

		<p><b>Fraglich bleibt:</b> Welche weiteren Maße gibt es, die auf diesem Prinzip aufbauen und wie kann man diese berechnen? Wie werden die Axiome von Kolmogoroff formal definiert? Wie funktioniert Kombinatorik und Permutation?
		Wie rechnet man mit Mengen und was ist eigentlich eine Ereignismenge? Welche Regeln gelten für Mengenoperationen? Wie rechnet man mit Wahrscheinlichkeiten? Was ist der Multiplikationssatz und was ist totale Wahrscheinlichkeit?</p>

		<p>Gemeinsam können wir diese Fragen und weitere gerne beantworten. Schreibe mir einfach eine Mail.</p>

		</div>
		</div>

	</main>
<script>
//Get the button
var mybutton = document.getElementById("myBtn");

// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}
	</script>

</body>

</html>
